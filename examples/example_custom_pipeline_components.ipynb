{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: Creating Custom Pipeline Components\n",
    "\n",
    "**Requirements**: The mexca package must be installed with the components `spe`, `tra`, and `sen`. This can be done with the command `!pip install mexca[spe,tra,sen]`.\n",
    "\n",
    "In this notebook, we will create a new customized component for mexca. All five components in the MEXCA pipeline can be replaced by customized components as long as they have an `apply` method which receives the same input and produces the same output as the standard components.\n",
    "\n",
    "In this example, we will replace the sentiment extraction component with a new component that predicts topic probabilities for each transcribed sentence. For the topic prediction, we use a pretrained [DeBERTa](https://huggingface.co/docs/transformers/v4.34.1/en/model_doc/deberta#overview) cross-encoder model for natural language inference provided by the SentenceTransformers package on [Hugging Face Hub](https://huggingface.co/cross-encoder/nli-deberta-base). The model predicts topic probabilities via zero-shot classification which is explained in more detail in this [blog post](https://joeddav.github.io/blog/2020/05/29/ZSL.html). It is implemented in PyTorch using the transformers package.\n",
    "\n",
    "## Creating the Custom Component\n",
    "\n",
    "First, let's import the modules and classes that we need for the new component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "import os\n",
    "from typing import Any, Dict, List, Optional\n",
    "\n",
    "from tqdm import tqdm\n",
    "from intervaltree import IntervalTree, Interval\n",
    "from IPython.display import Video\n",
    "from urllib.request import urlopen\n",
    "from mexca.audio import SpeakerIdentifier\n",
    "from mexca.data import (\n",
    "    BaseData,\n",
    "    AudioTranscription,\n",
    "    SentimentAnnotation,\n",
    "    TranscriptionData,\n",
    ")\n",
    "from mexca.pipeline import Pipeline\n",
    "from mexca.text import AudioTranscriber, SentimentExtractor\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    DebertaForSequenceClassification,\n",
    ")\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we actually create the new component, let's dive into the architecture of the `SentimentExtractor` component that we want to replace. As all components, it has an `apply` method which takes an `AudioTranscription` object as input and returns an `SentimentAnnotation` as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Signature (self, transcription: mexca.data.AudioTranscription, show_progress: bool = True) -> mexca.data.SentimentAnnotation>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inspect.signature(SentimentExtractor.apply)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our new topic extraction component will also work with audio transcription input, so we can leave the input as it is. However, it will return a different output, namely, an annotation with topic probabilities for each sentence. For our new component, we will create a new subclass from `SentimentAnnotation` to store topic probabilities. The `SentimentAnnotation` class stores data in an `IntervalTree` object which contains `Interval` objects. In our case, each `Interval` object stores data about one sentence, including our topic probabilities. Let's create a new class for storing topic data for a single sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTopicData(BaseData):\n",
    "    \"\"\"Store topic probabilities for a single sentence.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    text: str\n",
    "        Sentence text.\n",
    "    topics: dict\n",
    "        Probabilities (values) for each topic (keys).\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    text: str\n",
    "    topics: Dict[str, float]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we create a subclass of `SentimentAnnotation` which stores the data for all sentences. `SentimentAnnotation` has the properties `data_type` (indicating which data class is stored in the segments) and `serialization_name` (used for automatic JSON serialization) which we override in our custom subclass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTopicAnnotation(SentimentAnnotation):\n",
    "    \"\"\"Store topic annotations for transcribed sentences.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    filename: pydantic.FilePath\n",
    "        Path to the transcribed file. Must point to a valid file.\n",
    "    segments: intervaltree.Intervaltree\n",
    "        Interval tree containing segments with topic data for all sentences.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Override abstract properties\n",
    "    @property\n",
    "    def data_type(self) -> Any:\n",
    "        CustomTopicData\n",
    "\n",
    "    @property\n",
    "    def serialization_name(self) -> str:\n",
    "        return \"topic_annotation\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now completely defined the output of our topic extractor component. In the next step, we create the new component itself. We create the `CustomTopicExtractor` class as a subclass of the `SentimentExtractor` class to inherit its methods and properties. First, override the constructor method (i.e., `__init__`) and add a new argument `topic` to it. This way, we can specify for which topics the component should predict probabilities. Second, we override the `classifier` property to load the pretrained DeBERTa model. Our implementation uses lazy initialization, so the model is only loaded into memory, when we access it for the first time. This can save memory and improve performance.\n",
    "\n",
    "N.B.: mexca uses lazy initialization for all standard components to avoid loading the pretrained models into memory at the same time. This reduces the occurrence of runtime errors because not enough working memory is available and improves performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTopicExtractor(SentimentExtractor):\n",
    "    def __init__(\n",
    "        self,\n",
    "        topics: List[str],\n",
    "        model_name: Optional[str] = None,\n",
    "        device: Optional[torch.device] = None,\n",
    "    ):\n",
    "        super().__init__(model_name, device)\n",
    "        self.topics = topics\n",
    "\n",
    "    @property\n",
    "    def classifier(self) -> DebertaForSequenceClassification:\n",
    "        \"\"\"The pretrained sequence classification model for topic prediction.\n",
    "        Loaded automatically from `model_name`.\n",
    "        \"\"\"\n",
    "        if not self._classifier:\n",
    "            self._classifier = (\n",
    "                AutoModelForSequenceClassification.from_pretrained(\n",
    "                    self.model_name,\n",
    "                ).to(self.device)\n",
    "            )\n",
    "\n",
    "        return self._classifier\n",
    "\n",
    "    def apply(\n",
    "        self, transcription: AudioTranscription, show_progress: bool = True\n",
    "    ) -> CustomTopicAnnotation:\n",
    "        \"\"\"Extract topic probabilities from text.\n",
    "\n",
    "        Iterates over the sentences in the audio transcription and predicts topic probabilities.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        transcription: AudioTranscription\n",
    "            The transcription of the speech segments in the audio fie split into sentences.\n",
    "            Returned by `AudioTranscriber`.\n",
    "        show_progress: bool, optional, default=True\n",
    "            Whether a progress bar is displayed or not.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        CustomTopicAnnotation\n",
    "            An data class object with the topic probabilities\n",
    "            for each sentence.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # Create output object with empty interval tree\n",
    "        topic_annotation = CustomTopicAnnotation(\n",
    "            filename=transcription.filename, segments=IntervalTree()\n",
    "        )\n",
    "\n",
    "        # Interate over sentences (this could be optimized by batching sentences)\n",
    "        for sent in tqdm(\n",
    "            transcription.segments,\n",
    "            total=len(transcription.segments),\n",
    "            disable=not show_progress,\n",
    "        ):\n",
    "            # Transform text and topics into tokens\n",
    "            tokens = self.tokenizer(\n",
    "                [sent.data.text for _ in self.topics],\n",
    "                self.topics,\n",
    "                padding=True,\n",
    "                return_tensors=\"pt\",\n",
    "            ).to(self.device)\n",
    "            # Get model predictions\n",
    "            output = self.classifier(**tokens)\n",
    "            # Transform logits to probabilities (scores)\n",
    "            logits = output.logits.detach().cpu()\n",
    "            # Omit neutral scores (dim 2) and only take contradiction (dim 0) and entailment (dim 1) scores\n",
    "            scores = logits[:, [0, 1]].softmax(dim=1)\n",
    "            # Add probabilities and topics to output\n",
    "            topic_annotation.segments.add(\n",
    "                Interval(\n",
    "                    begin=sent.begin,\n",
    "                    end=sent.end,\n",
    "                    # Use custom data class\n",
    "                    data=CustomTopicData(\n",
    "                        text=sent.data.text,\n",
    "                        topics={\n",
    "                            key: val\n",
    "                            for (key, val) in zip(self.topics, scores[:, 1])\n",
    "                        },\n",
    "                    ),\n",
    "                )\n",
    "            )\n",
    "\n",
    "        return topic_annotation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The custom topic extraction component is now complete. In the next section, we will apply it to two examples.\n",
    "\n",
    "## Applying the Custom Component\n",
    "\n",
    "### Test Example\n",
    "\n",
    "Let's apply our new `CustomTopicExtractor` component to a test case. We first create an instance of the component class with three topics: Trade, Justice, and Migration. We also specify the name of the pretrained model on Hugging Face Hub. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = [\"trade\", \"justice\", \"migration\"]\n",
    "\n",
    "extractor = CustomTopicExtractor(\n",
    "    topics=topics,\n",
    "    model_name=\"cross-encoder/nli-deberta-base\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we create some test input data. We construct an interval tree with intervals for two sentences and add it to an `AudioTranscription` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = IntervalTree(\n",
    "    [\n",
    "        Interval(\n",
    "            begin=0.0,\n",
    "            end=1.0,\n",
    "            data=TranscriptionData(\n",
    "                index=0, text=\"This deal will greatly boost our economy.\"\n",
    "            ),\n",
    "        ),\n",
    "        Interval(\n",
    "            begin=1.0,\n",
    "            end=2.0,\n",
    "            data=TranscriptionData(\n",
    "                index=1, text=\"The country decided to open its borders.\"\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "transcription = AudioTranscription(\n",
    "    filename=\"debate.mp4\",\n",
    "    segments=sentences,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use the `AudioAnnotation` object as input for the `apply` method of our topic extractor component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:01<00:00,  1.34it/s]\n"
     ]
    }
   ],
   "source": [
    "result = extractor.apply(transcription)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's iterate over the result and print the topic probabilities for each sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'trade': 0.9688225388526917, 'justice': 0.0038643144071102142, 'migration': 0.030821722000837326}\n",
      "{'trade': 0.6463996767997742, 'justice': 0.015696685761213303, 'migration': 0.7641936540603638}\n"
     ]
    }
   ],
   "source": [
    "for seg in result.segments:\n",
    "    print(seg.data.topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the first sentence, the Trade topic has by far the highest probability, that is, the topic is most likely entailed in the sentence. The second sentence, however, entails Trade and Migration to a similar extent since borders can refer both topics.\n",
    "\n",
    "### Real-world example\n",
    "\n",
    "We can also include our custom component in a MEXCA pipeline and apply it to a real world example. We will use a video of the US presidential debate between Clinton and Trump in 2016 which can be found on [YouTube](https://www.youtube.com/watch?v=DBhrSdjePkk). First, let's download the video from a third-party website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_example(url, filename):\n",
    "    # Check if filename exists\n",
    "    if not os.path.exists(filename):\n",
    "        video = urlopen(url)\n",
    "\n",
    "        with open(filename, \"wb\") as file:\n",
    "            file.write(video.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"debate.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_url = \"https://books.psychstat.org/rdata/data/debate.mp4\"\n",
    "filename = \"debate.mp4\"\n",
    "\n",
    "download_example(example_url, filename)\n",
    "\n",
    "Video(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we create a MEXCA pipeline with three components: An `SpeakerIdentifier` to detect speech segments, an `AudioTranscriber` component to transcribe the speech, and our `CustomTopicExtractor` to predict the topic probabilities. We specify that we want to detect speech for two different speaker. For the audio transcription, we select the smallest Whisper model to speed up the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(\n",
    "    speaker_identifier=SpeakerIdentifier(\n",
    "        num_speakers=2,\n",
    "        use_auth_token=\"HF_TOKEN\" # Replace this string with your token\n",
    "    ),\n",
    "    audio_transcriber=AudioTranscriber(whisper_model=\"tiny\"),\n",
    "    sentiment_extractor=extractor,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply the pipeline to the debate video. We specify that we only want to process the file from second 10 to second 30 and that the language is English. We also add that we don't want to merge the resulting output from the different components since we did not implement how our topic probabilities should be merged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:03<00:00,  9.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:11<00:00,  2.35s/it]\n",
      "100%|██████████| 10/10 [00:01<00:00,  6.59it/s]\n"
     ]
    }
   ],
   "source": [
    "output = pipeline.apply(\n",
    "    filepath=filename, process_subclip=(10, 30), language=\"en\", merge=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the transcribed speech segments and the most likely topic for each sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence:  Well, Donald, I know you live in your own reality, but that's \n",
      " Topic:  trade\n",
      "Sentence:  was against it once it was finally negotiated and the terms were laid out. \n",
      " Topic:  trade\n",
      "Sentence:  Do you need any other stuff? \n",
      " Topic:  trade\n",
      "Sentence:  Well, I hope. \n",
      " Topic:  justice\n",
      "Sentence:  called it the gold standard. \n",
      " Topic:  justice\n",
      "Sentence:  You called it the gold standard of trade deals. \n",
      " Topic:  trade\n",
      "Sentence:  He said it's the finest deal you've ever seen. \n",
      " Topic:  trade\n",
      "Sentence:  You called it the gold standard. \n",
      " Topic:  justice\n",
      "Sentence:  I wrote about that in. \n",
      " Topic:  trade\n",
      "Sentence:  And then you heard what I said about it, and all of a sudden you were against it. \n",
      " Topic:  trade\n"
     ]
    }
   ],
   "source": [
    "for seg in output.sentiment.segments:\n",
    "    topic = list(seg.data.topics.keys())[\n",
    "        torch.Tensor(list(seg.data.topics.values())).argmax()\n",
    "    ]\n",
    "\n",
    "    print(\"Sentence: \", seg.data.text, \"\\n Topic: \", topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The debate at this time interval seems to be mostly about trade deals. Also note how gold standard is more associated with Justice than Trade.\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "In this example, we created a custom component for extracting topic probabilities from transcribed text. This was done by creating a subclass from an existing mexca component and imitating it's input and output. This approach generally illustrates how new components for MEXCA can be created or existing components can be modified."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mexca",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
